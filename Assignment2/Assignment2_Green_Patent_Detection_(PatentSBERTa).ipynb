{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd8dc97",
   "metadata": {},
   "source": [
    "# M4: Assignment 2\n",
    "\n",
    "## Part A: Baseline Model (Frozen Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7aae081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentence-transformers scikit-learn pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "993ee5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers sentence-transformers scikit-learn pandas pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e920ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"huggingface-hub>=0.34.0,<1.0\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b96ebe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d480b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286845f576d5498fa0fa8e2098856db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data from HuggingFace\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"AI-Growth-Lab/patents_claims_1.5m_traim_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cf24f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'date', 'text', 'A01B', 'A01C', 'A01D', 'A01F', 'A01G', 'A01H', 'A01J', 'A01K', 'A01L', 'A01M', 'A01N', 'A21B', 'A21C', 'A21D', 'A22B', 'A22C', 'A23B', 'A23C', 'A23D', 'A23F', 'A23G', 'A23J', 'A23K', 'A23L', 'A23N', 'A23P', 'A23V', 'A23Y', 'A24B', 'A24C', 'A24D', 'A24F', 'A41B', 'A41C', 'A41D', 'A41F', 'A41G', 'A41H', 'A42B', 'A42C', 'A43B', 'A43C', 'A43D', 'A44B', 'A44C', 'A44D', 'A45B', 'A45C', 'A45D', 'A45F', 'A46B', 'A46D', 'A47B', 'A47C', 'A47D', 'A47F', 'A47G', 'A47H', 'A47J', 'A47K', 'A47L', 'A61B', 'A61C', 'A61D', 'A61F', 'A61G', 'A61H', 'A61J', 'A61K', 'A61L', 'A61M', 'A61N', 'A61P', 'A61Q', 'A62B', 'A62C', 'A62D', 'A63B', 'A63C', 'A63D', 'A63F', 'A63G', 'A63H', 'A63J', 'A63K', 'B01B', 'B01D', 'B01F', 'B01J', 'B01L', 'B02B', 'B02C', 'B03B', 'B03C', 'B03D', 'B04B', 'B04C', 'B05B', 'B05C', 'B05D', 'B06B', 'B07B', 'B07C', 'B08B', 'B09B', 'B09C', 'B21B', 'B21C', 'B21D', 'B21F', 'B21G', 'B21H', 'B21J', 'B21K', 'B21L', 'B22C', 'B22D', 'B22F', 'B23B', 'B23C', 'B23D', 'B23F', 'B23G', 'B23H', 'B23K', 'B23P', 'B23Q', 'B24B', 'B24C', 'B24D', 'B25B', 'B25C', 'B25D', 'B25F', 'B25G', 'B25H', 'B25J', 'B26B', 'B26D', 'B26F', 'B27B', 'B27C', 'B27D', 'B27F', 'B27G', 'B27H', 'B27J', 'B27K', 'B27L', 'B27M', 'B27N', 'B28B', 'B28C', 'B28D', 'B29B', 'B29C', 'B29D', 'B29K', 'B29L', 'B30B', 'B31B', 'B31C', 'B31D', 'B31F', 'B32B', 'B33Y', 'B41B', 'B41C', 'B41D', 'B41F', 'B41G', 'B41J', 'B41K', 'B41L', 'B41M', 'B41N', 'B41P', 'B42B', 'B42C', 'B42D', 'B42F', 'B42P', 'B43K', 'B43L', 'B43M', 'B44B', 'B44C', 'B44D', 'B44F', 'B60B', 'B60C', 'B60D', 'B60F', 'B60G', 'B60H', 'B60J', 'B60K', 'B60L', 'B60M', 'B60N', 'B60P', 'B60Q', 'B60R', 'B60S', 'B60T', 'B60V', 'B60W', 'B60Y', 'B61B', 'B61C', 'B61D', 'B61F', 'B61G', 'B61H', 'B61J', 'B61K', 'B61L', 'B62B', 'B62C', 'B62D', 'B62H', 'B62J', 'B62K', 'B62L', 'B62M', 'B63B', 'B63C', 'B63G', 'B63H', 'B63J', 'B64B', 'B64C', 'B64D', 'B64F', 'B64G', 'B65B', 'B65C', 'B65D', 'B65F', 'B65G', 'B65H', 'B66B', 'B66C', 'B66D', 'B66F', 'B67B', 'B67C', 'B67D', 'B68B', 'B68C', 'B68F', 'B68G', 'B81B', 'B81C', 'B82B', 'B82Y', 'C01B', 'C01C', 'C01D', 'C01F', 'C01G', 'C01P', 'C02F', 'C03B', 'C03C', 'C04B', 'C05B', 'C05C', 'C05D', 'C05F', 'C05G', 'C06B', 'C06C', 'C06D', 'C07B', 'C07C', 'C07D', 'C07F', 'C07G', 'C07H', 'C07J', 'C07K', 'C08B', 'C08C', 'C08F', 'C08G', 'C08H', 'C08J', 'C08K', 'C08L', 'C09B', 'C09C', 'C09D', 'C09F', 'C09G', 'C09H', 'C09J', 'C09K', 'C10B', 'C10C', 'C10F', 'C10G', 'C10H', 'C10J', 'C10K', 'C10L', 'C10M', 'C10N', 'C11B', 'C11C', 'C11D', 'C12C', 'C12F', 'C12G', 'C12H', 'C12J', 'C12L', 'C12M', 'C12N', 'C12P', 'C12Q', 'C12R', 'C12Y', 'C13B', 'C13K', 'C14B', 'C14C', 'C21B', 'C21C', 'C21D', 'C22B', 'C22C', 'C22F', 'C23C', 'C23D', 'C23F', 'C23G', 'C25B', 'C25C', 'C25D', 'C25F', 'C30B', 'C40B', 'D01B', 'D01C', 'D01D', 'D01F', 'D01G', 'D01H', 'D02G', 'D02H', 'D02J', 'D03C', 'D03D', 'D03J', 'D04B', 'D04C', 'D04D', 'D04G', 'D04H', 'D05B', 'D05C', 'D05D', 'D06B', 'D06C', 'D06F', 'D06G', 'D06H', 'D06J', 'D06L', 'D06M', 'D06N', 'D06P', 'D06Q', 'D07B', 'D10B', 'D21B', 'D21C', 'D21D', 'D21F', 'D21G', 'D21H', 'D21J', 'E01B', 'E01C', 'E01D', 'E01F', 'E01H', 'E02B', 'E02C', 'E02D', 'E02F', 'E03B', 'E03C', 'E03D', 'E03F', 'E04B', 'E04C', 'E04D', 'E04F', 'E04G', 'E04H', 'E05B', 'E05C', 'E05D', 'E05F', 'E05G', 'E05Y', 'E06B', 'E06C', 'E21B', 'E21C', 'E21D', 'E21F', 'F01B', 'F01C', 'F01D', 'F01K', 'F01L', 'F01M', 'F01N', 'F01P', 'F02B', 'F02C', 'F02D', 'F02F', 'F02G', 'F02K', 'F02M', 'F02N', 'F02P', 'F03B', 'F03C', 'F03D', 'F03G', 'F03H', 'F04B', 'F04C', 'F04D', 'F04F', 'F05B', 'F05C', 'F05D', 'F15B', 'F15C', 'F15D', 'F16B', 'F16C', 'F16D', 'F16F', 'F16G', 'F16H', 'F16J', 'F16K', 'F16L', 'F16M', 'F16N', 'F16P', 'F16S', 'F16T', 'F17B', 'F17C', 'F17D', 'F21H', 'F21K', 'F21L', 'F21S', 'F21V', 'F21W', 'F21Y', 'F22B', 'F22D', 'F22G', 'F23B', 'F23C', 'F23D', 'F23G', 'F23H', 'F23J', 'F23K', 'F23L', 'F23M', 'F23N', 'F23Q', 'F23R', 'F24B', 'F24C', 'F24D', 'F24F', 'F24H', 'F24J', 'F24S', 'F24T', 'F24V', 'F25B', 'F25C', 'F25D', 'F25J', 'F26B', 'F27B', 'F27D', 'F27M', 'F28B', 'F28C', 'F28D', 'F28F', 'F28G', 'F41A', 'F41B', 'F41C', 'F41F', 'F41G', 'F41H', 'F41J', 'F42B', 'F42C', 'F42D', 'G01B', 'G01C', 'G01D', 'G01F', 'G01G', 'G01H', 'G01J', 'G01K', 'G01L', 'G01M', 'G01N', 'G01P', 'G01Q', 'G01R', 'G01S', 'G01T', 'G01V', 'G01W', 'G02B', 'G02C', 'G02F', 'G03B', 'G03C', 'G03D', 'G03F', 'G03G', 'G03H', 'G04B', 'G04C', 'G04D', 'G04F', 'G04G', 'G04R', 'G05B', 'G05D', 'G05F', 'G05G', 'G06C', 'G06D', 'G06E', 'G06F', 'G06G', 'G06J', 'G06K', 'G06M', 'G06N', 'G06Q', 'G06T', 'G07B', 'G07C', 'G07D', 'G07F', 'G07G', 'G08B', 'G08C', 'G08G', 'G09B', 'G09C', 'G09D', 'G09F', 'G09G', 'G10B', 'G10C', 'G10D', 'G10F', 'G10G', 'G10H', 'G10K', 'G10L', 'G11B', 'G11C', 'G12B', 'G16B', 'G16C', 'G16H', 'G16Z', 'G21B', 'G21C', 'G21D', 'G21F', 'G21G', 'G21H', 'G21J', 'G21K', 'G21Y', 'H01B', 'H01C', 'H01F', 'H01G', 'H01H', 'H01J', 'H01K', 'H01L', 'H01M', 'H01P', 'H01Q', 'H01R', 'H01S', 'H01T', 'H02B', 'H02G', 'H02H', 'H02J', 'H02K', 'H02M', 'H02N', 'H02P', 'H02S', 'H03B', 'H03C', 'H03D', 'H03F', 'H03G', 'H03H', 'H03J', 'H03K', 'H03L', 'H03M', 'H04B', 'H04H', 'H04J', 'H04K', 'H04L', 'H04M', 'H04N', 'H04Q', 'H04R', 'H04S', 'H04W', 'H05B', 'H05C', 'H05F', 'H05G', 'H05H', 'H05K', 'Y02A', 'Y02B', 'Y02C', 'Y02D', 'Y02E', 'Y02P', 'Y02T', 'Y02W', 'Y04S', 'Y10S', 'Y10T'],\n",
       "        num_rows: 1372910\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'date', 'text', 'A01B', 'A01C', 'A01D', 'A01F', 'A01G', 'A01H', 'A01J', 'A01K', 'A01L', 'A01M', 'A01N', 'A21B', 'A21C', 'A21D', 'A22B', 'A22C', 'A23B', 'A23C', 'A23D', 'A23F', 'A23G', 'A23J', 'A23K', 'A23L', 'A23N', 'A23P', 'A23V', 'A23Y', 'A24B', 'A24C', 'A24D', 'A24F', 'A41B', 'A41C', 'A41D', 'A41F', 'A41G', 'A41H', 'A42B', 'A42C', 'A43B', 'A43C', 'A43D', 'A44B', 'A44C', 'A44D', 'A45B', 'A45C', 'A45D', 'A45F', 'A46B', 'A46D', 'A47B', 'A47C', 'A47D', 'A47F', 'A47G', 'A47H', 'A47J', 'A47K', 'A47L', 'A61B', 'A61C', 'A61D', 'A61F', 'A61G', 'A61H', 'A61J', 'A61K', 'A61L', 'A61M', 'A61N', 'A61P', 'A61Q', 'A62B', 'A62C', 'A62D', 'A63B', 'A63C', 'A63D', 'A63F', 'A63G', 'A63H', 'A63J', 'A63K', 'B01B', 'B01D', 'B01F', 'B01J', 'B01L', 'B02B', 'B02C', 'B03B', 'B03C', 'B03D', 'B04B', 'B04C', 'B05B', 'B05C', 'B05D', 'B06B', 'B07B', 'B07C', 'B08B', 'B09B', 'B09C', 'B21B', 'B21C', 'B21D', 'B21F', 'B21G', 'B21H', 'B21J', 'B21K', 'B21L', 'B22C', 'B22D', 'B22F', 'B23B', 'B23C', 'B23D', 'B23F', 'B23G', 'B23H', 'B23K', 'B23P', 'B23Q', 'B24B', 'B24C', 'B24D', 'B25B', 'B25C', 'B25D', 'B25F', 'B25G', 'B25H', 'B25J', 'B26B', 'B26D', 'B26F', 'B27B', 'B27C', 'B27D', 'B27F', 'B27G', 'B27H', 'B27J', 'B27K', 'B27L', 'B27M', 'B27N', 'B28B', 'B28C', 'B28D', 'B29B', 'B29C', 'B29D', 'B29K', 'B29L', 'B30B', 'B31B', 'B31C', 'B31D', 'B31F', 'B32B', 'B33Y', 'B41B', 'B41C', 'B41D', 'B41F', 'B41G', 'B41J', 'B41K', 'B41L', 'B41M', 'B41N', 'B41P', 'B42B', 'B42C', 'B42D', 'B42F', 'B42P', 'B43K', 'B43L', 'B43M', 'B44B', 'B44C', 'B44D', 'B44F', 'B60B', 'B60C', 'B60D', 'B60F', 'B60G', 'B60H', 'B60J', 'B60K', 'B60L', 'B60M', 'B60N', 'B60P', 'B60Q', 'B60R', 'B60S', 'B60T', 'B60V', 'B60W', 'B60Y', 'B61B', 'B61C', 'B61D', 'B61F', 'B61G', 'B61H', 'B61J', 'B61K', 'B61L', 'B62B', 'B62C', 'B62D', 'B62H', 'B62J', 'B62K', 'B62L', 'B62M', 'B63B', 'B63C', 'B63G', 'B63H', 'B63J', 'B64B', 'B64C', 'B64D', 'B64F', 'B64G', 'B65B', 'B65C', 'B65D', 'B65F', 'B65G', 'B65H', 'B66B', 'B66C', 'B66D', 'B66F', 'B67B', 'B67C', 'B67D', 'B68B', 'B68C', 'B68F', 'B68G', 'B81B', 'B81C', 'B82B', 'B82Y', 'C01B', 'C01C', 'C01D', 'C01F', 'C01G', 'C01P', 'C02F', 'C03B', 'C03C', 'C04B', 'C05B', 'C05C', 'C05D', 'C05F', 'C05G', 'C06B', 'C06C', 'C06D', 'C07B', 'C07C', 'C07D', 'C07F', 'C07G', 'C07H', 'C07J', 'C07K', 'C08B', 'C08C', 'C08F', 'C08G', 'C08H', 'C08J', 'C08K', 'C08L', 'C09B', 'C09C', 'C09D', 'C09F', 'C09G', 'C09H', 'C09J', 'C09K', 'C10B', 'C10C', 'C10F', 'C10G', 'C10H', 'C10J', 'C10K', 'C10L', 'C10M', 'C10N', 'C11B', 'C11C', 'C11D', 'C12C', 'C12F', 'C12G', 'C12H', 'C12J', 'C12L', 'C12M', 'C12N', 'C12P', 'C12Q', 'C12R', 'C12Y', 'C13B', 'C13K', 'C14B', 'C14C', 'C21B', 'C21C', 'C21D', 'C22B', 'C22C', 'C22F', 'C23C', 'C23D', 'C23F', 'C23G', 'C25B', 'C25C', 'C25D', 'C25F', 'C30B', 'C40B', 'D01B', 'D01C', 'D01D', 'D01F', 'D01G', 'D01H', 'D02G', 'D02H', 'D02J', 'D03C', 'D03D', 'D03J', 'D04B', 'D04C', 'D04D', 'D04G', 'D04H', 'D05B', 'D05C', 'D05D', 'D06B', 'D06C', 'D06F', 'D06G', 'D06H', 'D06J', 'D06L', 'D06M', 'D06N', 'D06P', 'D06Q', 'D07B', 'D10B', 'D21B', 'D21C', 'D21D', 'D21F', 'D21G', 'D21H', 'D21J', 'E01B', 'E01C', 'E01D', 'E01F', 'E01H', 'E02B', 'E02C', 'E02D', 'E02F', 'E03B', 'E03C', 'E03D', 'E03F', 'E04B', 'E04C', 'E04D', 'E04F', 'E04G', 'E04H', 'E05B', 'E05C', 'E05D', 'E05F', 'E05G', 'E05Y', 'E06B', 'E06C', 'E21B', 'E21C', 'E21D', 'E21F', 'F01B', 'F01C', 'F01D', 'F01K', 'F01L', 'F01M', 'F01N', 'F01P', 'F02B', 'F02C', 'F02D', 'F02F', 'F02G', 'F02K', 'F02M', 'F02N', 'F02P', 'F03B', 'F03C', 'F03D', 'F03G', 'F03H', 'F04B', 'F04C', 'F04D', 'F04F', 'F05B', 'F05C', 'F05D', 'F15B', 'F15C', 'F15D', 'F16B', 'F16C', 'F16D', 'F16F', 'F16G', 'F16H', 'F16J', 'F16K', 'F16L', 'F16M', 'F16N', 'F16P', 'F16S', 'F16T', 'F17B', 'F17C', 'F17D', 'F21H', 'F21K', 'F21L', 'F21S', 'F21V', 'F21W', 'F21Y', 'F22B', 'F22D', 'F22G', 'F23B', 'F23C', 'F23D', 'F23G', 'F23H', 'F23J', 'F23K', 'F23L', 'F23M', 'F23N', 'F23Q', 'F23R', 'F24B', 'F24C', 'F24D', 'F24F', 'F24H', 'F24J', 'F24S', 'F24T', 'F24V', 'F25B', 'F25C', 'F25D', 'F25J', 'F26B', 'F27B', 'F27D', 'F27M', 'F28B', 'F28C', 'F28D', 'F28F', 'F28G', 'F41A', 'F41B', 'F41C', 'F41F', 'F41G', 'F41H', 'F41J', 'F42B', 'F42C', 'F42D', 'G01B', 'G01C', 'G01D', 'G01F', 'G01G', 'G01H', 'G01J', 'G01K', 'G01L', 'G01M', 'G01N', 'G01P', 'G01Q', 'G01R', 'G01S', 'G01T', 'G01V', 'G01W', 'G02B', 'G02C', 'G02F', 'G03B', 'G03C', 'G03D', 'G03F', 'G03G', 'G03H', 'G04B', 'G04C', 'G04D', 'G04F', 'G04G', 'G04R', 'G05B', 'G05D', 'G05F', 'G05G', 'G06C', 'G06D', 'G06E', 'G06F', 'G06G', 'G06J', 'G06K', 'G06M', 'G06N', 'G06Q', 'G06T', 'G07B', 'G07C', 'G07D', 'G07F', 'G07G', 'G08B', 'G08C', 'G08G', 'G09B', 'G09C', 'G09D', 'G09F', 'G09G', 'G10B', 'G10C', 'G10D', 'G10F', 'G10G', 'G10H', 'G10K', 'G10L', 'G11B', 'G11C', 'G12B', 'G16B', 'G16C', 'G16H', 'G16Z', 'G21B', 'G21C', 'G21D', 'G21F', 'G21G', 'G21H', 'G21J', 'G21K', 'G21Y', 'H01B', 'H01C', 'H01F', 'H01G', 'H01H', 'H01J', 'H01K', 'H01L', 'H01M', 'H01P', 'H01Q', 'H01R', 'H01S', 'H01T', 'H02B', 'H02G', 'H02H', 'H02J', 'H02K', 'H02M', 'H02N', 'H02P', 'H02S', 'H03B', 'H03C', 'H03D', 'H03F', 'H03G', 'H03H', 'H03J', 'H03K', 'H03L', 'H03M', 'H04B', 'H04H', 'H04J', 'H04K', 'H04L', 'H04M', 'H04N', 'H04Q', 'H04R', 'H04S', 'H04W', 'H05B', 'H05C', 'H05F', 'H05G', 'H05H', 'H05K', 'Y02A', 'Y02B', 'Y02C', 'Y02D', 'Y02E', 'Y02P', 'Y02T', 'Y02W', 'Y04S', 'Y10S', 'Y10T'],\n",
       "        num_rows: 119384\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a9981c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the green label (is_green_silver)\n",
    "\n",
    "train_df = dataset['train'].to_pandas()\n",
    "test_df = dataset['test'].to_pandas()\n",
    "\n",
    "y02_columns = ['Y02A', 'Y02B', 'Y02C', 'Y02D', 'Y02E', 'Y02P', 'Y02T', 'Y02W']\n",
    "\n",
    "# Create green label: 1 if any Y02 column = 1, else 0\n",
    "train_df['is_green_silver'] = train_df[y02_columns].max(axis=1)\n",
    "test_df['is_green_silver'] = test_df[y02_columns].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9861d3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample balanced data (25k green + 25k not green)\n",
    "\n",
    "# Separate green and not green patents from train set\n",
    "green_patents = train_df[train_df['is_green_silver'] == 1]\n",
    "not_green_patents = train_df[train_df['is_green_silver'] == 0]\n",
    "\n",
    "# Sample 25k from each\n",
    "green_sample = green_patents.sample(n=25000, random_state=42)\n",
    "not_green_sample = not_green_patents.sample(n=25000, random_state=42)\n",
    "\n",
    "# Combine into 50k balanced dataset\n",
    "patents_50k_green = pd.concat([green_sample, not_green_sample]).sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6db6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom splits and prepare columns\n",
    "\n",
    "# Split into train_silver (40k) and eval_silver (10k)\n",
    "patents_50k_green['split'] = (\n",
    "    ['train_silver'] * 40000 +\n",
    "    ['pool_unlabeled'] * 5000 +\n",
    "    ['eval_silver'] * 5000 \n",
    ")\n",
    "\n",
    "# Keep only needed columns\n",
    "patents_50k_green = patents_50k_green[['id', 'date', 'text', 'is_green_silver', 'split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae85ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as parquet file\n",
    "patents_50k_green.to_parquet('patents_50k_green.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d79142fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the prepared dataset\n",
    "df = pd.read_parquet('patents_50k_green.parquet')\n",
    "\n",
    "# Split into train, pool unlabeled and eval\n",
    "train_df = df[df['split'] == 'train_silver'].reset_index(drop=True)\n",
    "pool_unlabeled_df = df[df['split'] == 'pool_unlabeled'].reset_index(drop=True)\n",
    "eval_df = df[df['split'] == 'eval_silver'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "103d8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('AI-Growth-Lab/PatentSBERTa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d40b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to create embeddings. This can take a while, so I've have saved the embeddings as .npy files in the repository.\n",
    "\n",
    "# Create embeddings. Converts each text into a 768 dimensional vector\n",
    "# train_embeddings = model.encode(train_df['text'].tolist(), show_progress_bar=True)\n",
    "# pool_unlabeled_embeddings = model.encode(pool_unlabeled_df['text'].tolist(), show_progress_bar=True)\n",
    "# eval_embeddings = model.encode(eval_df['text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save embeddings to file.\n",
    "\n",
    "# Save embeddings to file\n",
    "# np.save('train_embeddings.npy', train_embeddings)\n",
    "# np.save('pool_unlabeled_embeddings.npy', pool_unlabeled_embeddings)\n",
    "# np.save('eval_embeddings.npy', eval_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed7187f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-computed embeddings\n",
    "train_embeddings = np.load('train_embeddings.npy')\n",
    "pool_unlabeled_embeddings = np.load('pool_unlabeled_embeddings.npy')\n",
    "eval_embeddings = np.load('eval_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c099439e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 768)\n",
      "(5000, 768)\n",
      "(5000, 768)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the embeddings\n",
    "print(train_embeddings.shape)\n",
    "print(pool_unlabeled_embeddings.shape)\n",
    "print(eval_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b83f1c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Not Green       0.78      0.80      0.79      2466\n",
      "       Green       0.80      0.78      0.79      2534\n",
      "\n",
      "    accuracy                           0.79      5000\n",
      "   macro avg       0.79      0.79      0.79      5000\n",
      "weighted avg       0.79      0.79      0.79      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression classifier on frozen embeddings\n",
    "classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "classifier.fit(train_embeddings, train_df['is_green_silver'])\n",
    "\n",
    "# Evaluate on eval set\n",
    "predictions = classifier.predict(eval_embeddings)\n",
    "probabilities = classifier.predict_proba(eval_embeddings)\n",
    "\n",
    "# Report metrics\n",
    "print(classification_report(eval_df['is_green_silver'], predictions, \n",
    "                          target_names=['Not Green', 'Green']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c969d3",
   "metadata": {},
   "source": [
    "## Part B: Identify High-Risk Examples (Uncertainty Sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0745c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pool_unlabeled dataframe\n",
    "pool_df = df[df['split'] == 'pool_unlabeled'].reset_index(drop=True)\n",
    "\n",
    "# Get predicted probabilities for pool_unlabeled\n",
    "pool_probabilities = classifier.predict_proba(pool_unlabeled_embeddings)\n",
    "p_green = pool_probabilities[:, 1]\n",
    "\n",
    "# Compute uncertainty score: u = 1 - 2 * |p - 0.5|\n",
    "u = 1 - 2 * np.abs(p_green - 0.5)\n",
    "\n",
    "# Add to dataframe\n",
    "pool_df['p_green'] = p_green\n",
    "pool_df['u'] = u\n",
    "\n",
    "# Select top 100 highest uncertainty examples\n",
    "top_100 = pool_df.nlargest(100, 'u').reset_index(drop=True)\n",
    "\n",
    "# Export with empty labeling columns\n",
    "hitl_df = top_100[['id', 'text', 'p_green', 'u']].copy()\n",
    "hitl_df['human_label'] = ''\n",
    "hitl_df['notes'] = ''\n",
    "\n",
    "hitl_df.to_csv('hitl_green_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf187e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>p_green</th>\n",
       "      <th>u</th>\n",
       "      <th>human_label</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9647788</td>\n",
       "      <td>1. A system, comprising: a memory that stores ...</td>\n",
       "      <td>0.499949</td>\n",
       "      <td>0.999898</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8999166</td>\n",
       "      <td>1. A method for allowing access to the bottom ...</td>\n",
       "      <td>0.499604</td>\n",
       "      <td>0.999209</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8555568</td>\n",
       "      <td>1. A drain inlet vault comprising a plurality ...</td>\n",
       "      <td>0.499371</td>\n",
       "      <td>0.998741</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9637231</td>\n",
       "      <td>1. A method comprising: operating an aerial ve...</td>\n",
       "      <td>0.499266</td>\n",
       "      <td>0.998531</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9698560</td>\n",
       "      <td>1. A laser ignition system for an internal com...</td>\n",
       "      <td>0.499210</td>\n",
       "      <td>0.998419</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text   p_green  \\\n",
       "0  9647788  1. A system, comprising: a memory that stores ...  0.499949   \n",
       "1  8999166  1. A method for allowing access to the bottom ...  0.499604   \n",
       "2  8555568  1. A drain inlet vault comprising a plurality ...  0.499371   \n",
       "3  9637231  1. A method comprising: operating an aerial ve...  0.499266   \n",
       "4  9698560  1. A laser ignition system for an internal com...  0.499210   \n",
       "\n",
       "          u human_label notes  \n",
       "0  0.999898                    \n",
       "1  0.999209                    \n",
       "2  0.998741                    \n",
       "3  0.998531                    \n",
       "4  0.998419                    "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitl_df.head().sort_values(by='u', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70181f6b",
   "metadata": {},
   "source": [
    "## Part C: Implement LLM → Human HITL (Gold Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a1f8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part C: Implement LLM → Human HITL (Gold Labels)\n",
    "\n",
    "# Load the CSV from Part B\n",
    "hitl_df = pd.read_csv('hitl_green_100.csv')\n",
    "\n",
    "# Add new columns with correct data types\n",
    "hitl_df['llm_green_suggested'] = 0  # Initialize as integer\n",
    "hitl_df['llm_confidence'] = ''\n",
    "hitl_df['llm_rationale'] = ''\n",
    "hitl_df['is_green_human'] = 0  # Initialize as integer\n",
    "hitl_df['override'] = 0  # Initialize as integer\n",
    "\n",
    "# Save template for manual labeling\n",
    "hitl_df.to_csv('hitl_green_100_for_labeling.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "424b5783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/100...\n",
      "Processing 2/100...\n",
      "Processing 3/100...\n",
      "Processing 4/100...\n",
      "Processing 5/100...\n",
      "Processing 6/100...\n",
      "Processing 7/100...\n",
      "Processing 8/100...\n",
      "Processing 9/100...\n",
      "Processing 10/100...\n",
      "Processing 11/100...\n",
      "Processing 12/100...\n",
      "Processing 13/100...\n",
      "Processing 14/100...\n",
      "Processing 15/100...\n",
      "Processing 16/100...\n",
      "Processing 17/100...\n",
      "Processing 18/100...\n",
      "Processing 19/100...\n",
      "Processing 20/100...\n",
      "Processing 21/100...\n",
      "Processing 22/100...\n",
      "Processing 23/100...\n",
      "Processing 24/100...\n",
      "Processing 25/100...\n",
      "Processing 26/100...\n",
      "Processing 27/100...\n",
      "Processing 28/100...\n",
      "Processing 29/100...\n",
      "Processing 30/100...\n",
      "Processing 31/100...\n",
      "Processing 32/100...\n",
      "Processing 33/100...\n",
      "Processing 34/100...\n",
      "Processing 35/100...\n",
      "Processing 36/100...\n",
      "Processing 37/100...\n",
      "Processing 38/100...\n",
      "Processing 39/100...\n",
      "Processing 40/100...\n",
      "Processing 41/100...\n",
      "Processing 42/100...\n",
      "Processing 43/100...\n",
      "Processing 44/100...\n",
      "Processing 45/100...\n",
      "Processing 46/100...\n",
      "Processing 47/100...\n",
      "Processing 48/100...\n",
      "Processing 49/100...\n",
      "Processing 50/100...\n",
      "Processing 51/100...\n",
      "Processing 52/100...\n",
      "Processing 53/100...\n",
      "Processing 54/100...\n",
      "Processing 55/100...\n",
      "Processing 56/100...\n",
      "Processing 57/100...\n",
      "Processing 58/100...\n",
      "Processing 59/100...\n",
      "Processing 60/100...\n",
      "Processing 61/100...\n",
      "Processing 62/100...\n",
      "Processing 63/100...\n",
      "Processing 64/100...\n",
      "Processing 65/100...\n",
      "Processing 66/100...\n",
      "Processing 67/100...\n",
      "Processing 68/100...\n",
      "Processing 69/100...\n",
      "Processing 70/100...\n",
      "Processing 71/100...\n",
      "Processing 72/100...\n",
      "Processing 73/100...\n",
      "Processing 74/100...\n",
      "Processing 75/100...\n",
      "Processing 76/100...\n",
      "Processing 77/100...\n",
      "Processing 78/100...\n",
      "Processing 79/100...\n",
      "Processing 80/100...\n",
      "Processing 81/100...\n",
      "Processing 82/100...\n",
      "Processing 83/100...\n",
      "Processing 84/100...\n",
      "Processing 85/100...\n",
      "Processing 86/100...\n",
      "Processing 87/100...\n",
      "Processing 88/100...\n",
      "Processing 89/100...\n",
      "Processing 90/100...\n",
      "Processing 91/100...\n",
      "Processing 92/100...\n",
      "Processing 93/100...\n",
      "Processing 94/100...\n",
      "Processing 95/100...\n",
      "Processing 96/100...\n",
      "Processing 97/100...\n",
      "Processing 98/100...\n",
      "Processing 99/100...\n",
      "Processing 100/100...\n",
      "LLM evaluation complete. Review hitl_green_100_with_llm.csv and add human labels.\n"
     ]
    }
   ],
   "source": [
    "# LLM evaluation using Ollama\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def llm_evaluate_patent(text):\n",
    "    \"\"\"\n",
    "    Send patent text to Ollama and get green classification suggestion.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are an expert in green technology patents. Analyze this patent claim and determine if it relates to climate change mitigation or green technology (Y02 classification).\n",
    "\n",
    "Patent Claim:\n",
    "{text}\n",
    "\n",
    "Provide your response in exactly this format:\n",
    "Classification: [YES/NO]\n",
    "Confidence: [low/medium/high]\n",
    "Rationale: [1-3 sentences citing specific phrases from the claim]\n",
    "\"\"\"\n",
    "    \n",
    "    response = requests.post('http://localhost:11434/api/generate',\n",
    "                            json={\n",
    "                                \"model\": \"gemma3:1b\",  # or llama2, mistral, etc.\n",
    "                                \"prompt\": prompt,\n",
    "                                \"stream\": False,\n",
    "                                \"temperature\": 0.3\n",
    "                            })\n",
    "    \n",
    "    return response.json()['response']\n",
    "\n",
    "def parse_llm_response(response):\n",
    "    \"\"\"\n",
    "    Parse LLM response to extract structured fields.\n",
    "    \"\"\"\n",
    "    # Extract classification\n",
    "    classification_match = re.search(r'Classification:\\s*(YES|NO)', response, re.IGNORECASE)\n",
    "    llm_green = 1 if classification_match and classification_match.group(1).upper() == 'YES' else 0\n",
    "    \n",
    "    # Extract confidence\n",
    "    confidence_match = re.search(r'Confidence:\\s*(low|medium|high)', response, re.IGNORECASE)\n",
    "    confidence = confidence_match.group(1).lower() if confidence_match else 'unknown'\n",
    "    \n",
    "    # Extract rationale\n",
    "    rationale_match = re.search(r'Rationale:\\s*(.+)', response, re.IGNORECASE | re.DOTALL)\n",
    "    rationale = rationale_match.group(1).strip() if rationale_match else response\n",
    "    \n",
    "    return llm_green, confidence, rationale\n",
    "\n",
    "# Process each row with LLM\n",
    "for idx, row in hitl_df.iterrows():\n",
    "    print(f\"Processing {idx+1}/100...\")\n",
    "    llm_response = llm_evaluate_patent(row['text'])\n",
    "    llm_green, confidence, rationale = parse_llm_response(llm_response)\n",
    "    \n",
    "    hitl_df.at[idx, 'llm_green_suggested'] = llm_green\n",
    "    hitl_df.at[idx, 'llm_confidence'] = confidence\n",
    "    hitl_df.at[idx, 'llm_rationale'] = rationale\n",
    "\n",
    "# Save with LLM suggestions\n",
    "hitl_df.to_csv('hitl_green_100_with_llm.csv', index=False)\n",
    "print(\"LLM evaluation complete. Review hitl_green_100_with_llm.csv and add human labels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7d37a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human overrode LLM in 89 out of 100 cases (89%)\n",
      "\n",
      "Example overrides:\n",
      "        id                                               text  \\\n",
      "1  8999166  1. A method for allowing access to the bottom ...   \n",
      "2  8555568  1. A drain inlet vault comprising a plurality ...   \n",
      "3  9637231  1. A method comprising: operating an aerial ve...   \n",
      "\n",
      "   llm_green_suggested  is_green_human  \\\n",
      "1                    1               0   \n",
      "2                    1               0   \n",
      "3                    1               0   \n",
      "\n",
      "                                       llm_rationale  notes  \n",
      "1  The claim details a process for accessing a wa...    NaN  \n",
      "2  The claim describes a structure designed for w...    NaN  \n",
      "3  The claim details a method for aerial vehicle ...    NaN  \n"
     ]
    }
   ],
   "source": [
    "# Human review step\n",
    "# After manually adding 'is_green_human' column to the CSV, run this:\n",
    "\n",
    "hitl_final = pd.read_csv('hitl_green_100_with_llm.csv')\n",
    "\n",
    "# Calculate overrides\n",
    "hitl_final['override'] = (hitl_final['llm_green_suggested'] != hitl_final['is_green_human']).astype(int)\n",
    "override_count = hitl_final['override'].sum()\n",
    "\n",
    "print(f\"Human overrode LLM in {override_count} out of 100 cases ({override_count}%)\")\n",
    "\n",
    "# Show examples of overrides\n",
    "override_examples = hitl_final[hitl_final['override'] == 1][['id', 'text', 'llm_green_suggested', 'is_green_human', 'llm_rationale', 'notes']].head(3)\n",
    "print(\"\\nExample overrides:\")\n",
    "print(override_examples)\n",
    "\n",
    "# Save final labeled dataset\n",
    "hitl_final.to_csv('hitl_green_100_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592c5fd4",
   "metadata": {},
   "source": [
    "## Part D: Final Model (Fine-Tune PatentSBERTa Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55558e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part D: Final Model (Fine-Tune PatentSBERTa Once)\n",
    "\n",
    "# Load HITL gold labels\n",
    "hitl_gold = pd.read_csv('hitl_green_100_final.csv')\n",
    "\n",
    "# Create is_green_gold column for the full dataset\n",
    "# Start with silver labels\n",
    "df['is_green_gold'] = df['is_green_silver']\n",
    "\n",
    "# Override with gold labels for the 100 HITL examples\n",
    "for _, row in hitl_gold.iterrows():\n",
    "    df.loc[df['id'] == row['id'], 'is_green_gold'] = row['is_green_human']\n",
    "\n",
    "# Prepare training data (train_silver + gold_100)\n",
    "train_gold_df = df[df['split'].isin(['train_silver', 'pool_unlabeled'])].copy()\n",
    "train_gold_df = train_gold_df[train_gold_df['id'].isin(df[df['split'] == 'train_silver']['id']) | \n",
    "                               train_gold_df['id'].isin(hitl_gold['id'])]\n",
    "\n",
    "eval_df = df[df['split'] == 'eval_silver'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23f934dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MPNetForSequenceClassification were not initialized from the model checkpoint at AI-Growth-Lab/PatentSBERTa and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e60d0fed32d4e8eb9c1d19a3a53732e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f1421c68e34426a88c23af9c886799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/j7sn5bzx5vdghf56k4w50qrm0000gn/T/ipykernel_27876/1118025669.py:53: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice:\u001b[34m\u001b[1mwandb\u001b[0m: You chose \"Don't visualize my results\"\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using W&B in offline mode.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.24.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory. Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing.<br>Run data is saved locally in <code>/Users/alexander_christiansen/Desktop/_Kandidat/2. semester/M4 - Applied Deep Learning and Artificial Intelligence/Notebooks/BDS-Deep-Learning-Assignments/Assignment2/wandb/offline-run-20260219_222251-vzk604e1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander_christiansen/Desktop/_Kandidat/2. semester/M4 - Applied Deep Learning and Artificial Intelligence/Notebooks/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2507' max='2507' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2507/2507 42:37, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.403135</td>\n",
       "      <td>0.819400</td>\n",
       "      <td>0.816699</td>\n",
       "      <td>0.829913</td>\n",
       "      <td>0.823253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2507, training_loss=0.44703318666641484, metrics={'train_runtime': 2580.3216, 'train_samples_per_second': 15.541, 'train_steps_per_second': 0.972, 'total_flos': 5275376659968000.0, 'train_loss': 0.44703318666641484, 'epoch': 1.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune PatentSBERTa\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained('AI-Growth-Lab/PatentSBERTa')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('AI-Growth-Lab/PatentSBERTa', num_labels=2)\n",
    "\n",
    "# Prepare datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_gold_df[['text', 'is_green_gold']])\n",
    "train_dataset = train_dataset.rename_column('is_green_gold', 'labels')\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "eval_dataset = Dataset.from_pandas(eval_df[['text', 'is_green_gold']])\n",
    "eval_dataset = eval_dataset.rename_column('is_green_gold', 'labels')\n",
    "eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# ADD THIS FUNCTION - compute metrics for evaluation\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    ")\n",
    "\n",
    "# Trainer - ADD compute_metrics parameter\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Fine-tune\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "063a3f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander_christiansen/Desktop/_Kandidat/2. semester/M4 - Applied Deep Learning and Artificial Intelligence/Notebooks/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on eval_silver:\n",
      "{'eval_loss': 0.4031352400779724, 'eval_accuracy': 0.8194, 'eval_precision': 0.8166990291262136, 'eval_recall': 0.82991318074191, 'eval_f1': 0.8232530827950675, 'eval_runtime': 97.1147, 'eval_samples_per_second': 51.485, 'eval_steps_per_second': 3.223, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7144aa11ff9546399897ad1fdc988742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexander_christiansen/Desktop/_Kandidat/2. semester/M4 - Applied Deep Learning and Artificial Intelligence/Notebooks/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n",
      "/Users/alexander_christiansen/Desktop/_Kandidat/2. semester/M4 - Applied Deep Learning and Artificial Intelligence/Notebooks/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results on gold_100:\n",
      "{'eval_loss': 0.8510827422142029, 'eval_accuracy': 0.44, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_runtime': 1.9399, 'eval_samples_per_second': 51.548, 'eval_steps_per_second': 3.608, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./patent_sberta_finetuned/tokenizer_config.json',\n",
       " './patent_sberta_finetuned/special_tokens_map.json',\n",
       " './patent_sberta_finetuned/vocab.txt',\n",
       " './patent_sberta_finetuned/added_tokens.json',\n",
       " './patent_sberta_finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate on eval_silver\n",
    "eval_results = trainer.evaluate(eval_dataset)\n",
    "print(\"Results on eval_silver:\")\n",
    "print(eval_results)\n",
    "\n",
    "# Evaluate on gold_100\n",
    "gold_dataset = Dataset.from_pandas(hitl_gold[['text', 'is_green_human']])\n",
    "gold_dataset = gold_dataset.rename_column('is_green_human', 'labels')\n",
    "gold_dataset = gold_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "gold_results = trainer.evaluate(gold_dataset)\n",
    "print(\"\\nResults on gold_100:\")\n",
    "print(gold_results)\n",
    "\n",
    "# Save fine-tuned model\n",
    "model.save_pretrained('./patent_sberta_finetuned')\n",
    "tokenizer.save_pretrained('./patent_sberta_finetuned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
